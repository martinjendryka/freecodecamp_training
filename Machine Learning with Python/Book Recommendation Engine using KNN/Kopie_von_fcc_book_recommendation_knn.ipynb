{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this challenge, you will create a book recommendation algorithm using K-Nearest Neighbors.\n",
        "\n",
        "You will use the Book-Crossings dataset. This dataset contains 1.1 million ratings (scale of 1-10) of 270,000 books by 90,000 users.\n",
        "\n",
        "After importing and cleaning the data, use NearestNeighbors from sklearn.neighbors to develop a model that shows books that are similar to a given book. The Nearest Neighbors algorithm measures the distance to determine the â€œclosenessâ€ of instances.\n",
        "\n",
        "Create a function named get_recommends that takes a book title (from the dataset) as an argument and returns a list of 5 similar books with their distances from the book argument.\n",
        "\n",
        "This code:\n",
        "\n",
        "get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\")\n",
        "should return:\n",
        "\n",
        "[\n",
        "  'The Queen of the Damned (Vampire Chronicles (Paperback))',\n",
        "  [\n",
        "    ['Catch 22', 0.793983519077301],\n",
        "    ['The Witching Hour (Lives of the Mayfair Witches)', 0.7448656558990479],\n",
        "    ['Interview with the Vampire', 0.7345068454742432],\n",
        "    ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5376338362693787],\n",
        "    ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.5178412199020386]\n",
        "  ]\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "Notice that the data returned from get_recommends() is a list. The first element in the list is the book title passed into the function. The second element in the list is a list of five more lists. Each of the five lists contains a recommended book and the distance from the recommended book to the book passed into the function."
      ],
      "metadata": {
        "id": "xopxlC-3ASrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed76bde4-5fc5-4f09-c6b8-c1535160d27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 15:09:30--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26085508 (25M) [application/zip]\n",
            "Saving to: â€˜book-crossings.zipâ€™\n",
            "\n",
            "book-crossings.zip  100%[===================>]  24.88M   149MB/s    in 0.2s    \n",
            "\n",
            "2024-03-24 15:09:30 (149 MB/s) - â€˜book-crossings.zipâ€™ saved [26085508/26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "outputs": [],
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you graph the dataset (optional), you will notice that most books are not rated frequently. To ensure statistical significance, remove from the dataset users with less than 200 ratings and books with less than 100 ratings."
      ],
      "metadata": {
        "id": "BHE0AXnsAfh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAcXjkCFCh0A"
      },
      "outputs": [],
      "source": [
        "# clean data for statistical significance\n",
        "num_ratings= df_ratings.groupby('user').size()\n",
        "usersinclude  = num_ratings[num_ratings>=200].index # users with less than 200 ratings\n",
        "num_ratings= df_ratings.groupby('isbn').size()\n",
        "booksinclude  = num_ratings[num_ratings>=100].index # books with less than 100 ratings (independent of the users)\n",
        "ratings_new = df_ratings[df_ratings['user'].isin(usersinclude)]\n",
        "ratings_new = ratings_new[ratings_new['isbn'].isin(booksinclude)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge df_books and ratings_new\n",
        "merged_df = pd.merge(df_books, ratings_new, on='isbn', how='inner')\n",
        "merged_df_clean = merged_df.drop_duplicates([\"title\", \"user\"]) # remove all duplicates (otherwise .pivot does not work)\n",
        "\n",
        "df_pivot = merged_df_clean.pivot(index='title', columns='user', values='rating').fillna(0) # fillna is required\n"
      ],
      "metadata": {
        "id": "zGQqKHfTAXxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the KNN model\n",
        "n_neighbors = 5\n",
        "nbrs_model = NearestNeighbors(n_neighbors=n_neighbors+1,algorithm='auto',metric='cosine').fit(df_pivot.values) # n_neigbors needs one more to include the book title we want to find additional 5 books; cosine is needed, otherwise output differs from test solution\n"
      ],
      "metadata": {
        "id": "Y2kCEkwoAXsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\"):\n",
        "  distances,indices = nbrs_model.kneighbors(df_pivot.loc[book].values.reshape(1,-1)) # get neighbors for the book title, reshape required for function\n",
        "  distances= distances.flatten().tolist()\n",
        "  indices= indices.flatten().tolist()\n",
        "\n",
        "  nearest_books= df_pivot.index[indices[1:]].tolist()\n",
        "  nearest_books_dist = distances[1:]\n",
        "  book_list=[]\n",
        "\n",
        "  for i in range(len(nearest_books)-1,0,-1): # reversed order required since solution wants title with highest distance first\n",
        "    book_list.append([nearest_books[i],nearest_books_dist[i]])\n",
        "\n",
        "  recommended_books = [df_pivot.index[indices[0]],book_list]\n",
        "\n",
        "  return recommended_books"
      ],
      "metadata": {
        "id": "778OxfO3AXqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd2SLCh8oxMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad9d9fd-e9f1-4fc0-82ce-e0f465d8f27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Where the Heart Is (Oprah's Book Club (Paperback))\", [[\"I'll Be Seeing You\", 0.8016210794448853], ['The Weight of Water', 0.7708583474159241], ['The Surgeon', 0.7699410915374756], ['I Know This Much Is True', 0.7677075266838074]]]\n",
            "You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2):\n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}